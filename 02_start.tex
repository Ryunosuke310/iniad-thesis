\chapter{日本におけるAI政策議論の始動} %ここに枠組みを配置する

\section{国際的なルール形成と日本の貢献}

日本は、AIに関する国際的なルール形成において、初期から主導的な役割を担ってきた。
その起点となったのが、2016年のG7香川・高松情報通信大臣会合で示された「AIの研究開発原則」である。
これは、AIがもたらす影響について、国際社会が初めて共通の方向性を示したという点で歴史的な意義を持つ。

このG7での議論を踏まえ、2019年には「AIに関するOECD原則」が策定された。
この原則は、同年6月に日本が主催したG20大阪サミットにおいて「G20 AI原則」として承認され、より広範な国家間の共通指針となった。
さらに、2023年には再び日本がG7議長国として「広島AIプロセス」を立ち上げ、生成AIのリスクとガバナンスに関する国際的なルール作りの議論を主導している。

\section{国内における制度設計の経緯}
こうした国際的な貢献と並行し、日本国内でも制度設計に向けた議論が段階的に進められてきた。
特に、広島AIプロセスが立ち上がった2023年5月以降、「AIに関する暫定的な論点整理」の公表や、事業者向けの「AI事業者ガイドライン」の策定・改訂が活発に行われた。

これらの動きを統合し、より包括的な法制度のあり方を検討するため、2024年7月にはAI戦略会議の下に「AI制度研究会」が設置された。
同研究会での集中的な検討を経て、2025年2月4日に「AI制度に関する中間とりまとめ」が公表された。

この中間とりまとめで示された方向性を基に、さらなる法制化の作業が進められ、2025年9月1日にAI法が全面施行されると共に、AI戦略担当大臣が発令された。
(Todo:中間とりまとめから引用したことをしっかり記載する)
