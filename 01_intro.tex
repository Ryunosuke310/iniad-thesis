\chapter{はじめに}

\section{研究の背景}
ディープラーニングが提唱された2006年以降、AIは想像をはるかに超える速度で発展を続けている。
特に生成AIは、テキスト、画像、音声などを高精度で生成できるようになり、その性能は驚くほど向上した。
このようなAIは、これまで人間が行ってきた作業を代替するだけでなく、それ以上の新たな価値を創造できると期待されている。
実際に、医療や教育といった多岐にわたる分野で活用が進んでおり、今後も利用は拡大していくと考えられる。

一方で、AIの利用には多様なリスクが伴う。例えば、ハルシネーションと呼ばれる誤った情報の生成や、
プロセスのブラックボックス化による透明性の欠如といった問題が指摘されている。
また、高精度なフェイクコンテンツが作成可能になったことで、悪意ある利用が社会に甚大な損害をもたらす可能性もある。
AIは社会に大きな恩恵をもたらす有用なツールであると同時に、利用方法を適切に規制できなければ有害なものへと転じうる。
したがって、その両面性を理解した上で、適切な制度設計を行うことが喫緊の課題となっている。

%ここで日本のAI戦略会議の流れを軽く説明した方がよいかも？

\section{研究の目的}
本稿の目的は、主要国(EU、アメリカ、韓国)のAIに関する制度設計を比較分析し、
それを通じて我が国の社会の特性に適したAI規制・規律のあり方を提言することにある。
まず、AIになぜ規制・規律が必要なのかという根源的な問いに対し、
アシロマ原則や生命倫理といったこれまでの議論を基に理論的考察を行う。
次に、この考察を土台として主要国のAI関連法案を横断的に調査・分析し、その共通点と相違点を明らかにする。
最終的に、これらの国際比較と理論的考察から得られた知見を統合し、
AIの利便性と安全性を両立させる日本のAI法案の具体的な姿(望ましい法制度)を提示する。

\section{先行研究}


