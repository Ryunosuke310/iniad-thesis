\chapter{各国のAI規制状況の比較}

前章では、AIに対する法規制の必要性を論じた。それを受け本章では、主要国・国際組織におけるAI規制の具体的な動向を比較分析する。

具体的には、包括的な法制化を進めるEU、分野別の規律を重視するアメリカ、そして韓国、中国、さらには国連における議論を取り上げ、そのアプローチの違いと共通点を明らかにする。

この比較検討を通じて、後の章で展開する日本のAI規制への提言に向けた、多角的な示唆を得ることを目的とする。

\section{諸外国との比較}

AIへの規制アプローチは、国や地域の事情を反映して多様な姿を見せている。本節ではその具体的な動向を概観するにあたり、まず世界で最も包括的かつ先行する法規制として知られるEUの「AI Act」を分析の起点とする。
これを基準とすることで、アメリカの分野別アプローチや、アジア各国の独自のアプローチとの違いがより明確になるからである。
%（※この章でどのようなものさしで比較するかについて述べる方法もあり）

\subsection{EU}
EUは2024年に世界で初めて包括的かつ法的拘束力を持つ「AI Act」\cite{EUArtifi77:online}を成立させ、AI規制に関する国際的な議論をリードする存在となっている。
その最大の特徴は、AIがもたらすリスクを4段階に分類し、リスクの程度に応じて異なる義務を課す「リスクベース・アプローチ」を基本設計に採用した点にある。
また適用範囲は域外適用の原則をとっており、EU域外の事業者にも影響を及ぼすものとなっている。

\subsubsection{禁止されるAI行為}
人間の尊厳や権利を侵害する、社会的に許容できないリスクをもたらすAIの利用を原則として禁止している。

主な禁止事項は以下の通りである。

\begin{itemize}
  \item 潜在意識に働きかけたり、操作したり、欺瞞的な手法を用いて行動を歪め、十分な情報に基づいた意思決定を阻害し、重大な危害を引き起こすこと
  \item 年齢、障害、または社会経済的状況に関連する脆弱性を悪用して行動を歪め、重大な危害を引き起こすこと
  \item 合法的に取得された生体認証データセットのラベル付けやフィルタリング、または法執行機関が生体認証データを分類する場合を除き、機密属性（人種、政治的意見、労働組合への加入、宗教的または哲学的信念、性生活、性的指向）を推測する生体認証分類システム
  \item 社会的スコアリング、すなわち、社会的行動や個人的な特徴に基づいて個人またはグループを評価または分類し、それらの人々に有害または不利な扱いを引き起こすこと
  \item プロファイリングや性格特性のみに基づいて個人が犯罪を犯すリスクを評価すること(ただし、犯罪行為に直接関連する客観的かつ検証可能な事実に基づく人間による評価を補強するために使用される場合は除く)
  \item インターネットや CCTV 映像から顔画像を無差別にスクレイピングして顔認識データベースを作成すること
  \item 医療上または安全上の理由を除き、職場や教育機関において感情を推測すること
  \item 法執行機関が公的にアクセス可能なスペースで「リアルタイム」のリモート生体認証 (RBI) を実施することはできない（テロ防止や重大犯罪の容疑者特定など、限定された例外有り）
\end{itemize}

\subsubsection{高リスクAIシステム}
社会や人々の権利に重大な影響を及ぼす可能性があるAIは「高リスク」と定義され、義務が課される。AIシステムが「高リスク」とみなされるのは、主に以下の2つのケースである。

\begin{itemize}
    \item EU法が定める製品の安全部品である場合:既存のEU法の対象となる製品、またはその安全部品としてAIが使われ、かつ第三者による適合性評価が求められる場合
    \item 特定の用途(ユースケース)に該当する場合:リストアップされている特定の分野・用途でAIが使用される場合(以下に記述)
\end{itemize}

以下のような分野・用途で使われるAIシステムがリストアップされている。

\begin{itemize}
    \item 生体認証:遠隔生体認証システム（個人が本人であると確認する認証は除く）、人々の属性や特性を推測する生体分類システム、感情認識システム
    \item 重要インフラ:道路交通や、水、ガス、暖房、電気の供給管理における安全コンポーネント
    \item 教育・職業訓練: 教育機関へのアクセスや入学の決定、学習成果の評価、テスト中の不正行為の監視
    \item 雇用・労働者管理: 求人広告、応募書類の分析・フィルタリング、候補者の評価といった採用活動。昇進や契約終了の決定、タスクの割り当て、パフォーマンスの監視・評価
    \item 公共サービス・民間サービスへのアクセス: 公的機関による給付金の受給資格の評価。信用力の評価（金融詐欺の検出は除く）。警察、消防、医療などの緊急通報の評価と優先順位付け。生命保険や健康保険のリスク評価と価格設定
    \item 法執行: 個人が犯罪被害者になるリスクの評価。ポリグラフ（嘘発見器）。犯罪捜査における証拠の信頼性評価。個人の犯罪リスク評価。犯罪捜査中のプロファイリング
    \item 移民・亡命・国境管理: ポリグラフ。不法移民や健康上のリスク評価。亡命、ビザ、居住許可の申請審査。個人の識別(渡航文書の検証は除く)
    \item 司法及び民主的プロセス: 事実の解釈や法律の適用にAIを使用すること。選挙結果や投票行動に影響を与えること(キャンペーンの最適化ツールなど、人間と直接対話しないものは除く)
\end{itemize}

ただし、上記に該当する場合でも、AIが「狭い手続き的なタスクを実行する」「人間が行った活動の結果を改善する」など、リスクが低いとみなされる特定の条件下では、ハイリスクから除外される例外がある。

重要な例外として上記に該当するAIシステムが、個人のプロファイリング(仕事のパフォーマンス、経済状況、健康、好み、行動などを評価するための個人データの自動処理)を行う場合は、常にハイリスクとみなされる。

\subsubsection{高リスクAIシステムの提供者に課される要求事項}

高リスクAIシステムの提供者は、以下の義務を果たす必要がある。

\begin{itemize}
    \item リスク管理システムの確立: AIシステムのライフサイクル全体を通じてリスクを管理する体制を構築すること
    \item データガバナンスの実施: 学習、検証、テストに用いるデータセットが、目的に対して適切かつ十分な代表性を持ち、可能な限りエラーがなく、完全であることを保証すること
    \item 技術文書の作成: 法令遵守を証明し、当局が評価するために必要な技術文書を準備すること
    \item 記録保持機能の設計: リスクを特定するために重要なイベント（ログ）を自動的に記録できるようシステムを設計すること
    \item 下流の展開者向け取扱説明書の提供: システムを導入する事業者（展開者）が法令を遵守できるよう、適切な使用方法を記載した説明書を提供すること
    \item 人間による監視（ヒューマン・オーバーサイト）の実装: 展開者が人間による適切な監視を行えるようシステムを設計すること
    \item 適切なレベルの正確性、堅牢性、サイバーセキュリティの確保
    \item 品質管理システムの確立: 法令遵守を確実にするための品質管理体制を構築すること
\end{itemize}

\subsubsection{新たな規制対象:汎用AI(GPAI)モデル}
AI Actは、特定の用途に限定されないGPAIモデル、特に社会に広範な影響を与える「システミックリスク」を伴うモデルに対して、新たな義務を課している。

\subsubsection*{GPAIの定義}

GPAIの定義は以下の通りです。

\begin{itemize}
    \item 汎用AIモデル(GPAIモデル): 大量のデータを用いて自己教師あり学習などで訓練され、幅広いタスクを高い能力で実行できる、著しく汎用的なAIモデル。特定の製品として市場に出る前の、研究・開発・プロトタイピング段階のモデルは含まれない
    \item 汎用AIシステム(GPAIシステム): GPAIモデルを基盤とし、直接利用されたり、他のAIシステムに統合されたりするなど、多様な目的で利用できるAIシステム
\end{itemize}


\subsubsection*{全てのGPAIモデル提供者に課される義務}

GPAIモデルを提供する全ての事業者は、以下の義務を負う。

\begin{itemize}
    \item 技術文書の作成: 訓練・テストのプロセスや評価結果を含む技術文書を作成すること
    \item 下流の提供者への情報提供: GPAIモデルを自社のAIシステムに統合しようとする事業者(下流の提供者)に対し、そのモデルの能力や限界を理解させ、法令遵守を可能にするための情報や文書を提供すること
    \item 著作権指令を尊重する方針の確立: EUの著作権法を遵守するための方針を策定すること
    \item 訓練コンテンツの要約の公開: モデルの訓練に使用したコンテンツについて、十分に詳細な要約を公開すること
\end{itemize}

パラメータ(重み、モデルのアーキテクチャ、使用法など)が公開されている自由かつオープンなライセンスのGPAIモデルは、上記の3つ目と4つ目の義務のみを遵守すればよいとされている。
ただし、そのモデルが後述の「システミックリスク」を持つ場合は、この例外は適用されない。



\subsubsection*{システミックリスクを伴うGPAIモデル}

モデルの訓練に用いられた累積計算量が1025FLOPs(浮動小数点演算)を超える場合、「システミックリスク」を持つと見なされる。
その提供者は、この基準に達した場合、2週間以内に欧州委員会に通知する義務がある。

追加の義務は以下の通りである。

\begin{itemize}
    \item モデル評価の実施: システミックリスクを特定・軽減するため、敵対的テストを含むモデル評価を実施し、文書化すること
    \item システミックリスクの評価と軽減: 潜在的なシステミックリスクとその源泉を評価し、軽減措置を講じること
    \item 重大インシデントの追跡、文書化、報告: 重大なインシデントと是正措置の可能性について、遅滞なくAIオフィスおよび関連する国内管轄当局に報告すること
    \item サイバーセキュリティの確保: 適切なレベルのサイバーセキュリティ保護を保証すること
\end{itemize}


\subsubsection{限定的リスクと最小リスクAI}

上記以外にも、AI Actはリスクに応じた規律を定めている。

\begin{itemize}
    \item 限定的リスク:チャットボットやディープフェイクのように、人間がAIと対話していることを認識できない可能性がある場合、その旨を利用者に開示する透明性義務が課される
    \item 最小リスク:上記のいずれにも該当しない多くのAIアプリケーションは、最小リスクとみなされ、原則として規制の対象外となる
\end{itemize}


\subsubsection{執行と罰則}

AI Actの実効性を担保するため、EUレベルで監督を行う「AIオフィス」が設置される。
規則に違反した事業者には、最大で全世界の年間売上高の7\%または3500万ユーロのいずれか高い方が制裁金として科される可能性があり、極めて厳しい罰則規定となっている。

\subsection{アメリカ}

米国において、AI政策の方向性は極めて複雑な様相を呈している。第一の要因は、連邦レベルでの政権交代である。
バイデン前政権は、大統領令を通じてAIの安全性や国民の権利保護を最優先課題とし、リスク管理のための規制強化を推進した。
対照的に、トランプ現政権は「イノベーションの解放」を掲げ、開発の障壁となる規制の撤廃を行い、自由競争を最大化する方針へと大きく舵を切っている。

しかし、米国の動向を理解する上で、もう一つ見落とせない重要な要素がある。それは、連邦政府の規制緩和の動きに逆行するように進む、州レベルでの独自の規制強化である。
AI産業の中心地であるカリフォルニア州などは、連邦法の空白を埋めるべく、強力な州法による規範形成を主導している。

このように、連邦政府内での「方針転換」に加え、連邦と州の間での「ねじれ」までも内包する米国の事例は、日本がAI規制の在り方を検討する上で極めて重要な示唆を与える。
本節では、バイデン・トランプ両政権下の連邦政策に加え、カリフォルニア州による独自の法規制を含めた多層的な政策動向を詳細に分析する。

\subsubsection{バイデン前政権による政策}

バイデン前政権による政策は、国民の安全を優先し、AIがもたらすリスクを管理することを目的とした方針であった。
その集大成が、2023年10月30日に公表された「The Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence」(人工知能の安全・安心・信頼できる開発と利用に関する大統領令)である。
この大統領令は、包括的な法律の制定を待たず、既存の行政機関の権限を活用してAIのリスクに対応するよう命じるものである。

PwC Japanの整理\cite{amerika67:online}によると、主な内容は以下の通りである。

\subsubsection*{AI技術の安全・安心の確保}

\begin{itemize}
    \item デュアルユース基盤モデルに関する報告義務
    \item IaaS業者による外国ユーザー報告義務
    \item 重要なインフラのサイバーセキュリティ強化
    \item AIによる生成コンテンツのウォーターマーク検討
\end{itemize}

\subsubsection*{イノベーションと競争力強化}

\begin{itemize}
    \item AI人材の確保
    \item 特許権・IP法の明確化
\end{itemize}

\subsubsection*{労働者支援}

\begin{itemize}
    \item 労働市場におけるAI活用と影響に関するレポートとガイドラインの発行
\end{itemize}

\subsubsection*{公平と公民権推進}

\begin{itemize}
    \item 連邦政府機関での公民権強化、公正で公平な司法制度の確保
\end{itemize}

\subsubsection*{消費者、患者、交通機関利用者、学生の保護}

\begin{itemize}
    \item ヘルスケア、運輸、教育、通信関連の連邦政府機関によるAI活用推進
\end{itemize}

\subsubsection*{米国の国際的リーダーシップ推進}

\begin{itemize}
    \item 米国のAI基準・フレームワークの海外推進
\end{itemize}

%pwcまとめ

\subsubsection{トランプ政権による政策}

トランプ政権では、アメリカが人工知能における世界的優位の確立を目指し、他国との競争に勝利することで、人類の繁栄、経済競争力の強化、そしてアメリカ国民の国家安全保障という新たな時代を迎えることを目的としている。
この認識に基づき、「イノベーションの加速」、「インフラの構築」、「国際外交・安全保障における主導権」という3つの柱に基づくAIアクションプラン\cite{AIAction76:online}を策定した。

それぞれの項目は以下の通りである。

\subsubsection*{AIイノベーションを加速}

\begin{itemize}
    \item 煩雑な規制と煩雑な手続きの廃止
    \item Frontier AIが言論の自由とアメリカの価値観を守ることを保証
    \item オープンソースおよびオープンウェイトAIの奨励
    \item AI導入を可能にする
    \item AI時代のアメリカの労働者のエンパワーメント
    \item 次世代製造業をサポート
    \item AIを活用した科学への投資
    \item 世界クラスの科学データセットを構築する
    \item AI科学の進歩
    \item AIの解釈可能性、制御性、堅牢性のブレークスルーに投資する
    \item AI評価エコシステムの構築
    \item 政府におけるAI導入の加速
    \item 国防総省におけるAI導入を推進
    \item 民間および政府のAIイノベーションを保護する
    \item 法制度における合成メディアとの闘い
\end{itemize}

\subsubsection*{アメリカのAIインフラを構築する}

\begin{itemize}
    \item セキュリティを確保しながら、半導体製造施設やエネルギーインフラの許可手続きを簡素化
    \item AIイノベーションのペースに合わせたグリッドを開発する
    \item アメリカの半導体製造業の復活
    \item 軍事および諜報機関向けの高セキュリティデータセンターを構築
    \item AIインフラのための熟練した人材を育成する
    \item 重要インフラのサイバーセキュリティ強化  
    \item セキュアバイデザインAIテクノロジーとアプリケーションの推進
    \item AIインシデント対応のための成熟した連邦政府の能力を促進する
\end{itemize}

\subsubsection*{国際AI外交と安全保障をリードする}

\begin{itemize}
    \item アメリカのAIを同盟国やパートナーに輸出する
    \item 国際統治機関における中国の影響に対抗する
    \item AIコンピューティングの輸出管理の強化
    \item 既存の半導体製造輸出規制の抜け穴を塞ぐ
    \item 世界規模で保護対策を整合させる
    \item 米国政府がフロンティアモデルにおける国家安全保障リスクの評価の最前線に立つことを確保する
    \item バイオセキュリティへの投資
\end{itemize}

\subsubsection{連邦と州の「ねじれ」：カリフォルニア州による独自規制}

前述の通り、トランプ現政権下の連邦政府は、規制撤廃によるイノベーション推進へと大きく舵を切っている。
しかし、これはアメリカ全土が一枚岩で規制緩和に向かっていることを意味しない。
AI開発の世界的中心地であるカリフォルニア州は、連邦政府の動向とは対照的に、AIの安全性を確保するための強力な法的枠組みを独自に構築しており、実質的な規範形成を主導する構えを見せている。\cite{kariforuniamatome14:online}

カリフォルニア州議会では多数のAI関連法案が審議されているが、代表的な成立・審議法案は以下の通りである。

\begin{itemize}
    \item AB316(責任回避の禁止) : AIが関与した損害に対し、技術開発者・サービス提供者が「AIが自律的に損害を起こした」と主張したとしても、責任の免除をされないことを明確化する。\cite{AB316:online}
    \item AB489(医療資格の詐称禁止) : AIが医師などの医療専門職の免許や資格を有していると誤認させるような表現を用いることを禁止し、国民の安全を保護する。\cite{AB489:online}
    \item AB621(ディープフェイク被害救済) : ディープフェイクポルノの被害者に対し、個人の尊厳を守るための強力な救済措置を定める。\cite{AB621}
    \item SB53(AI安全開示法) : 最も包括的な規制の一つである。計算総量が$10^{26}$ FLOPを超える「フロンティアモデル」を対象とし、大規模開発者に対し、安全性計画の公開や重大インシデントの報告、内部告発者の保護を義務付ける。違反には1件あたり最大100万ドルの民事罰が科されるなど、実効性のあるハードローとして機能する。\cite{SB53matome:online} \cite{SB53:online}
\end{itemize}

このように、アメリカのAI規制は、規制緩和を進める「連邦(トランプ政権)」と、厳格な規制を志向する「州（カリフォルニア州等）」との間で、法的な「ねじれ」が生じている。
イノベーションの最先端を走る国家において、この二層構造がどのように機能し、あるいは対立していくのかは、日本の法制度設計にとっても極めて重要な観測点である。

\subsubsection{米国の政策動向の総括と日本への示唆}

バイデン前政権とトランプ現政権、そしてカリフォルニア州による独自の動き。これらを俯瞰すると、米国のAI政策は一見すると矛盾に満ちているように見えるが、そこには明確な対立軸と共通の目的意識が存在する。
本節では、「優先順位の対立」「連邦と州のねじれ」「共通点」という3つの視点から総括し、日本への示唆を導出する。

\subsubsection*{優先順位の対立：「国民の安全」と「国家の覇権」}

両政権の最大の違いは、AIガバナンスにおける最優先事項にある。
バイデン前政権の政策の中心は「国民の安全と信頼の確保」であった。大統領令が掲げる「AI技術の安全・安心の確保」や「公平と公民権推進」「労働者支援」といった項目は、AIがもたらすリスクから国民を保護することを第一の目的としていたことを示している。

対照的に、トランプ現政権の政策は「国家間の技術覇権競争」という認識が起点となっている。
「イノベーションの加速」や「国際AI外交と安全保障をリードする」といった柱は、AIを国家の競争力を左右する戦略的資産とみなしている。

\subsubsection*{連邦と州の「ねじれ」：規制緩和 vs 独自規制}

さらに、米国特有の現象として、連邦政府と州政府の間における法的な「ねじれ」が見過ごせない。トランプ政権下の連邦政府が「規制撤廃」へと突き進む一方で、AI産業の中心地であるカリフォルニア州は、SB53のような強力なハードローを成立させ、実質的な規制強化へと動いている。
これは、連邦レベルでの「空白」や「緩和」を、州レベルでの「厳格化」で埋めようとする拮抗状態であり、企業にとっては二重の対応を迫られる複雑な規制環境を生み出している。

\subsubsection*{共通点と日本への示唆}

アプローチや程度は異なるものの、いずれの主体も「AIにおける米国のリーダーシップを維持・強化する」という最終目的は完全に一致している。
しかし、米国の事例は、AIという新技術に対し、「国民の安全」と「国家の覇権」という価値観が政権交代によって極端に揺れ動き、さらに連邦と州の方針が食い違うことで、法的安定性が損なわれるリスクを浮き彫りにしている。

この「不安定性」こそが、日本にとっての最大の教訓である。日本が目指すべきは、政権や外圧によって方針が二転三転するような脆い構造ではない。
「国民の安全」を守るための最低限のハードローを国として確立し、その安定した土台の上で「イノベーション」を加速させるという、両者の持続的な調和である。


\subsection{中国}

アメリカとの技術覇権争いを背景にAI技術の急速な進化を国家目標とする中国は、同時にAIがもたらす社会的リスクを強く警戒しており、法制度の整備を急速に進めている。

EUの「AI Act」のような包括的な単一法典(包括的アプローチ)とは異なり、問題が顕在化した分野ごとに行政規則を迅速に制定・施行する分野別アプローチ(セクター方式)を採っている。
これは、社会に悪影響を与えると判断したリスクを即座に低減させつつ、規制対象外の分野ではイノベーションを阻害しないという、中国独自の戦略的な選択といえる。

本節では、多岐にわたるAI規制の中でも、特に「生成AI」と「ディープフェイク(深度合成)」に焦点を当て、その規制内容を分析する。

\subsubsection{生成AIサービス管理暫定弁法}

2022年末の生成AIの登場により、生成AIがもたらすリスクが大きくなった。その対応のために、生成AIサービス管理暫定弁法\cite{生成式人工智能服7:online}が2023年に制定された。

規制対象や内容については以下の通りである。

\subsubsection*{規制対象}

生成AI技術とは、テキスト、画像、音声、動画等のコンテンツを生成する能力を有するモデル及び関連技術を指す。

\subsubsection*{主な規制内容}

\begin{enumerate}
  \item \textbf{モデル開発段階における主たる義務}
  
  \begin{description}
    \item[学習に関する義務] \mbox{} \\[-3mm] % 見出しの横からリストを始めないための調整
    \begin{itemize}
      \item 適法なデータおよびベースモデルを利用する
      \item 他者の知的財産権を侵害してはならないこと
      \item 個人情報に関わる場合、本人の同意を得る又はその他法律および行政法規で定める事項に適合すること
      \item 訓練データの質を向上させ、訓練データの真正性、正確性、客観性及び多様性を高めるための効果的な措置を講ずること
      \item 法律および行政法規のそのほかの関連規定、及び関連主幹当局のそのほかの監督に関する要求を遵守すること
    \end{itemize}

    \item[データのラベリングに関する義務] \mbox{} \\[-3mm]
    \begin{itemize}
      \item 本弁法の要求に適合する明確、具体的かつ操作可能なラベリングルールを制定すること
      \item データラベリングの品質評価を実施し、ラベリングされた内容の正確性についてサンプル検証を行って確認すること
      \item ラベリング担当者に必要な訓練を行い、法律を尊重し、遵守する意識を高め、ラベリング担当者が標準的な方法でラベリングを実施するよう監督指導すること
    \end{itemize}

    \item[その他の義務] \mbox{} \\[-3mm]
    \begin{itemize}
      \item サービス契約締結義務
      \item 他の法令で安全評価が必要な場合の安全評価義務
      \item その他の法令に基づく許認可の取得義務
    \end{itemize}
  \end{description}

  \item \textbf{サービス提供段階における主たる義務}

  \begin{itemize}
    \item サービス提供段階の分類等級監督管理制度が規定
    \item 過度の依存の防止義務
    \item 個人情報保護義務
    \item サービスの安定性に関する義務
    \item 違法内容発見時の処置及び是正義務
    \item 苦情・通報メカニズムの構築義務
    \item 監督検査への協力義務
  \end{itemize}
\end{enumerate}

\subsubsection{インターネット情報サービス深度合成管理規定}

深層学習等の技術が、違法・有害情報の作成にも利用可能であることから、そのリスクに対応するために、2023年に施行された。

第2回のAI制度研究会で松尾弁護士が発表した資料\cite{matsuo_china_ai_2024}によると、内容は以下の通りである。

\subsubsection*{規制対象}

本規定によると、ディープシンセシス技術とは、ディープラーニング、バーチャルリアリティ等の、生成合成類型のアルゴリズムを利用して、
テキスト・画像・音声・映像・バーチャルシーン等のネットワーク情報を生成する技術をいうと定義されており、この技術が規制対象である。%（P15）

\subsubsection*{主な規制内容}

\begin{enumerate}
    \item 提供者の主な義務
    \begin{itemize}
        \item ディープシンセシス技術を利用したことの表示義務
        \item アルゴリズム届出義務 
    \end{itemize}

    \item 技術支持者の主な義務
    \begin{itemize}
        \item 訓練データ管理の強化及び生体識別情報編集機能に関する告知及び個別同意取得義務
        \item 合成類アルゴリズムメカニズムの定期的な監査評価義務及びセキュリティ評価義務
        \item アルゴリズム届出義務及び主管機関の検査への協力義務 
    \end{itemize} 

    \item 利用者の義務
    \begin{itemize}
        \item 虚偽のニュース情報の作成・複製・配信・伝播の禁止義務
    \end{itemize}

\end{enumerate}

\subsubsection{中国のAI規制に関する考察と日本への示唆}

中国のAIガバナンスは、AIが引き起こすリスクに対して、分野別に迅速な対応をするアプローチ方法を採用している。

一方日本は現在、包括的なAI規制法を作成し、執行しようとしている。
そのため、ハードローに関しては取り入れることが難しい。
しかし、リスクへの迅速な対応という姿勢は、日本が学ぶべき重要な点である。
迅速な対応が必要になる問題、あるいは法ではカバーしきれない細かな領域においてリスクが顕在化した場合、
迅速なガイドラインを策定・更新していくという補完的なアプローチは有効な手段となりうるだろう。

\subsection{韓国}

韓国は、EUのAI Actの議論と並行しつつ、それとは異なるアプローチでアジア初の包括的なAI規制法を整備した国である。
2024年12月に成立した「人工知能(AI)の発展と信頼基盤の構築に関する基本法(以下、AI基本法)」\cite{人工知能の発展と25:online}\cite{AIUpdat68:online}は、EUのリスクベース・アプローチを参考にしつつも、法の第一の目的に「AI産業の育成と国家競争力の強化」を掲げている点が最大の特徴である。

本節では、EUの規制と比較しつつ、韓国独自のバランス感覚が示されたAI基本法の主要な枠組みを分析する。

\subsubsection{AI基本法の概要}

\subsubsection*{対象となるAIの定義}

\begin{description}
    \item [人工知能] \mbox{} \\
    学習、推論、知覚、判断、言語の理解など、人間が持つ知的能力を電子的方法で具現したことをいう
    \item [人工知能システム] \mbox{} \\
    多様なレベルの自立性と適応性をもって与えられた目標のために、実際及び仮想環境に及ぼす予測、推薦、決定などの結果物を推論する人工知能ベースのシステムをいう
    \item [人工知能技術] \mbox{} \\
    人工知能を実現するために必要なハードウェア、ソフトウェア技術又はその活用技術をいう
    \item [高影響人工知能] \mbox{} \\
    人の生命、身体の安全及び基本権に重大な影響を及ぼしたり、危険を招く恐れがある人工知能システムとして、法律で上げる分野（エネルギー、飲料水、保健医療、原子力施設、犯罪捜査、交通手段等）で活用されるもの
    \item [生成系人工知能] \mbox{} \\
    入力したデータの構造と特性を模倣し、文、音、絵、映像、そのほかの様々な結果物を生成する人工知能システムをいう
\end{description}

\subsubsection*{対象となる事業者の定義}

\begin{description}
    \item [AI開発事業者] \mbox{} \\
    AIを開発し、提供する者
    \item [AI利用事業者] \mbox{} \\
    AI開発事業者が提供したAIを利用して、AI製品又はAIサービスを提供する者
\end{description}

\subsubsection*{適用範囲}

\begin{itemize}
    \item この法律は、国外で行われた行為でも国内市場または利用者に影響を及ぼす場合には適用する。
    \item この法律は、国防又は国家安全保障目的でのみ開発、利用される人工知能として大統領令で定める人工知能に対しては適用しない。
\end{itemize}

\subsubsection*{人工知能透明性確保義務}

\begin{itemize}
    \item 事業者は、高影響人工知能または、生成型人工知能を利用した製品又はサービスを提供しようとする場合、製品又はサービスが当該人工知能に基づいて運用されるという事実を利用者に事前に告知しなければならない.
    \item 事業者は、生成型人工知能又はこれを利用した製品又はサービスを提供する場合、その結果物が生成型人工知能によって生成されたという事実を表示しなければならない。
    \item 人工知能事業者は、人工知能システムを用いて実際と区別しにくい仮想の音響、画像又は映像等の結果物を提供する場合、当該結果物が人工知能システムによって生成されたという事実を利用者が明確に認識できる方法で告知又は表示しなければならない。この場合、当該結果物が芸術的・創造的表現物に該当するか、又はその一部を構成する場合には、展示又は香油等を阻害しない方法で告知又は表示することができる。
\end{itemize}

\subsubsection*{人工知能安全性確保義務}

\begin{itemize}
    \item 人工知能事業者は、学習に使用された累積演算量が大統領令で定める基準以上である人工知能システムの安全性を確保するために、次の各号の事項を履行しなければならない。
    \begin{enumerate}
        \item 人工知能ライフサイクル全般にわたるリスクの識別・評価及び緩和
        \item 人工知能関連の安全事故を監視し、対応するリスク管理体制の構築
    \end{enumerate}
\end{itemize}

\subsubsection*{高影響人工知能の確認}

\begin{itemize}
    \item 事業者は、人工知能またはそれを利用した製品・サービスを提供する場合、その人工知能が「高影響人工知能」に該当するかどうかを事前に検討しなければならない。また、必要な場合には、科学技術情報通信部長官に対し、「高影響人工知能」に該当するかどうかの確認を求めることができる。
\end{itemize}

\subsubsection*{高影響人工知能に関する事業者の責務}

\begin{enumerate}
    \item 人工知能事業者は、高影響人工知能又はこれを利用した製品・サービスを提供する場合、高影響人工知能の安全性・信頼性を確保するため、次の各号の内容を含む措置を大統領令で定めるところにより履行しなければならない。
    \begin{enumerate}
        \item リスク管理法案の樹立・運営
        \item 技術的に可能な範囲での人工知能が導出した最終結果、人工知能の最終結果導出に活用された主要基準、人工知能の開発・活用に用いられる学習用データの概要などについての説明方案の樹立・施行
        \item 利用者保護法案の樹立・運営
        \item 高影響人工知能に対する人の管理・監督
        \item 安全性・信頼性確保のための措置の内容を確認できる文書の作成と保管
        \item その他に高影響人工知能の安全性・信頼性確保のために委員会で審議・議決された事項
    \end{enumerate}
    \item 科学技術情報通信部長官は、第1項各号による措置の具体的な事項を定めて告示し、人工知能事業者にこれを遵守するよう勧告することができる。
    \item 人工知能事業者が他の法令により第1項各号に準ずる措置を大統領令で定めるところにより履行した場合には、第1項による措置を履行したものとみなす。
\end{enumerate}

\subsubsection*{高影響人工知能影響評価}

\begin{itemize}
    \item 人工知能事業者が高影響人工知能を利用した製品又はサービスを提供する場合、事前に人の基本権に及ぼす影響を評価（以下「影響評価」という）するために努力しなければならない。
    \item 国家機関等が高影響人工知能を利用した製品又はサービスを利用しようとする場合には、影響評価を実施した製品又はサービスを優先的に考慮しなければならない。
    \item その他影響評価の具体的な内容・方法等に関して必要な事項は、大統領令で定める。
\end{itemize}

\subsubsection*{国外事業者に関する義務}

一定規模以上(利用者数・売上高等が大統領令で定める基準に該当する者)の国外AI事業者は、国内代理人を指定し、届け出る義務を負う。国内代理人は、韓国国内に住所又は営業所を有する者とされている。
国内代理人は、以下の業務を代理する。

\begin{itemize}
    \item 大規模AIに関わる安全性確保措置の結果提出
    \item 高影響AIへの該当性の確認要請
    \item 高影響AIに関わる安瀬遠征・信頼性確保措置の実施支援
\end{itemize}

\subsubsection*{罰則}

3年以下の懲役又は3000万ウォン(約300万円)以下の罰金に処される。

\subsubsection{韓国のAI基本法に対する考察}

韓国のAI基本法は、EUのAI Actと類似した「包括的規制」であり、リスクベース・アプローチや域外適用といった共通点を持ちながらも、その規制哲学においては決定的な違いを示している。

\subsubsection*{罰則金の差}

罰則金の差異が違いの一つとして挙げられる。EUでは最大3500万ユーロ（約57億円）又は全世界年間売上高の7％の罰金が定められているが、韓国は最大3000万ウォン(約300万円)である。
このことから、罰則金を大きくすることによる、発展の妨害を緩めるためであることが推測できる。

\subsubsection*{日本への示唆：「国内代理人」制度の実効性}

もう一つの注目すべき点は、国外事業者に対する「国内代理人」の指定義務である。日本も現状、主要なAIサービスを国外事業者に依存している。
AIによる被害が発生した際の責任の所在や、日本の規制(たとえソフトローであっても)をいかに遵守させるかという実効性の担保は、日本にとって最大の課題である。
韓国の「国内代理人」制度は、この課題に対する一つの具体的な法的解決策であり、日本が将来の法整備を検討する上で、極めて重要な参考事例となるだろう。


%\subsection{国連}　ここいったん保留もしかしたら新しいところで執筆するかも

\section{各国比較の総括}

表\ref{tab:ai_comparison_full}に、主要国・地域におけるAI規制の現状と特徴を整理した。
\begin{table}[b]
\centering
\footnotesize % 4列表示のため文字サイズを縮小
\caption{AI規制の比較}
\label{tab:ai_comparison_full}
\begin{tabularx}{\textwidth}{|l|X|X|X|X|}
\hline
\textbf{項目} & \textbf{EU} & \textbf{韓国} & \textbf{中国} & \textbf{アメリカ(連邦レベル)} \\
\hline
\textbf{対象} & 
AIの影響を受ける人々 \par
(軍事・研究等は除外) & 
AI開発事業者、AI利用事業者 \par
(域外適用有り) \par
(国防、安全保障目的なら適用外) & 
中国のサービス提供者 \par
(域外適用有り) & 
特定のAI技術分野 \\
\hline
\textbf{規制方法} & 
リスクベースの \par
包括的ハードロー & 
リスクベースの \par
包括的ハードロー & 
法律による規制 \par
(国家による強い管理) & 
大統領令による規制 \par
基本的にはソフトロー \\
\hline
\textbf{リスク評価} & 
4段階のリスク分類 \par
(禁止・高・限定・最小) & 
健全性・安全性の確保 \par
徹底したリスク管理 & 
特定の技術指定 \par
(ディープフェイク等) & 
\\
\hline
\textbf{罰則規定} & 
制裁金(最大3500万ユーロ等) \par
市場からの取り下げ & 
3年以下の懲役 \par
3000万ウォン以下の罰金 \par
サービス提供停止 & 
行政処分(警告・通知) \par
治安管理責任・刑事責任 \par
サービス停止 &
\\
\hline
\textbf{その他} & 
(特記事項なし) & 
国外事業者は国内代理人を指定・届出 & 
(特記事項なし) & 
州法(加州等)による規制が存在 \\
\hline
\end{tabularx}
\end{table}
ここから読み取れるのは、各国がそれぞれの政治体制や経済戦略に基づき、異なる規制モデルを採用している点である。

EUは「基本権の保護」を最優先に掲げ、包括的なハードローによる厳格な規律を導入した。
韓国は、EUと同様に包括的な法体系を目指しつつも、産業振興とのバランスを考慮し、AIのリスク分類や罰則において独自のアプローチをとっている。
中国は分野別に即座に対応する方法をとっており、国家による強力な統制を行っている。
対照的に米国は、技術的優位性の維持を重視し、連邦レベルではソフトローを中心としたイノベーション重視の姿勢を維持している。
しかし、手法の違いこそあれ、「AIのリスクレベルに応じた管理(リスクベース・アプローチ)」を統治の基盤に置いている点では、各国とも共通している。これは、AIガバナンスが単なる倫理指針の段階を脱し、実効性を伴う制度設計のフェーズへと移行したことを示唆している。

なお、国連などの国際機関においても規範形成の議論が進められているが、法的拘束力を持つ具体的な制度設計という点では、
上述した主要4ヵ国・地域の動向が日本にとって最も直接的な参照モデルとなる。