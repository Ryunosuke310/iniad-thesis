\chapter{各国のAI規制状況の比較}

前章では、AIに対する法規制の必要性を論じた。それを受け本章では、主要国・国際組織におけるAI規制の具体的な動向を比較分析する。

具体的には、包括的な法制化を進めるEU、分野別の規律を重視するアメリカ、そして韓国、中国、さらには国連における議論を取り上げ、そのアプローチの違いと共通点を明らかにする。

この比較検討を通じて、後の章で展開する日本のAI規制への提言に向けた、多角的な示唆を得ることを目的とする。

\section{諸外国との比較}

AIへの規制アプローチは、国や地域の事情を反映して多様な姿を見せている。本節ではその具体的な動向を概観するにあたり、まず世界で最も包括的かつ先行する法規制として知られるEUの「AI Act」を分析の起点とする。
これを基準とすることで、アメリカの分野別アプローチや、アジア各国の独自のアプローチとの違いがより明確になるからである。
%（※この章でどのようなものさしで比較するかについて述べる方法もあり）

\subsection{EU}
EUは2024年に世界で初めて包括的かつ法的拘束力を持つ「AI Act」を成立させ、AI規制に関する国際的な議論をリードする存在となっている。
その最大の特徴は、AIがもたらすリスクを4段階に分類し、リスクの程度に応じて異なる義務を課す「リスクベース・アプローチ」を基本設計に採用した点にある。
また適用範囲は域外適用の原則をとっており、EU域外の事業者にも影響を及ぼすものとなっている。

\subsubsection{禁止されるAI行為}
人間の尊厳や権利を侵害する、社会的に許容できないリスクをもたらすAIの利用を原則として禁止している。

主な禁止事項は以下の通りである。

\begin{itemize}
  \item 潜在意識に働きかけたり、操作したり、欺瞞的な手法を用いて行動を歪め、十分な情報に基づいた意思決定を阻害し、重大な危害を引き起こすこと
  \item 年齢、障害、または社会経済的状況に関連する脆弱性を悪用して行動を歪め、重大な危害を引き起こすこと
  \item 合法的に取得された生体認証データセットのラベル付けやフィルタリング、または法執行機関が生体認証データを分類する場合を除き、機密属性（人種、政治的意見、労働組合への加入、宗教的または哲学的信念、性生活、性的指向）を推測する生体認証分類システム
  \item 社会的スコアリング、すなわち、社会的行動や個人的な特徴に基づいて個人またはグループを評価または分類し、それらの人々に有害または不利な扱いを引き起こすこと
  \item プロファイリングや性格特性のみに基づいて個人が犯罪を犯すリスクを評価すること(ただし、犯罪行為に直接関連する客観的かつ検証可能な事実に基づく人間による評価を補強するために使用される場合は除く)
  \item インターネットや CCTV 映像から顔画像を無差別にスクレイピングして顔認識データベースを作成すること
  \item 医療上または安全上の理由を除き、職場や教育機関において感情を推測すること
  \item 法執行機関が公的にアクセス可能なスペースで「リアルタイム」のリモート生体認証 (RBI) を実施することはできない（テロ防止や重大犯罪の容疑者特定など、限定された例外有り）
\end{itemize}

\subsubsection{高リスクAIシステム}
社会や人々の権利に重大な影響を及ぼす可能性があるAIは「高リスク」と定義され、義務が課される。AIシステムが「高リスク」とみなされるのは、主に以下の2つのケースである。

\begin{itemize}
    \item EU法が定める製品の安全部品である場合:既存のEU法の対象となる製品、またはその安全部品としてAIが使われ、かつ第三者による適合性評価が求められる場合
    \item 特定の用途(ユースケース)に該当する場合:リストアップされている特定の分野・用途でAIが使用される場合(以下に記述)
\end{itemize}

以下のような分野・用途で使われるAIシステムがリストアップされている。

\begin{itemize}
    \item 生体認証:遠隔生体認証システム（個人が本人であると確認する認証は除く）、人々の属性や特性を推測する生体分類システム、感情認識システム
    \item 重要インフラ:道路交通や、水、ガス、暖房、電気の供給管理における安全コンポーネント
    \item 教育・職業訓練: 教育機関へのアクセスや入学の決定、学習成果の評価、テスト中の不正行為の監視
    \item 雇用・労働者管理: 求人広告、応募書類の分析・フィルタリング、候補者の評価といった採用活動。昇進や契約終了の決定、タスクの割り当て、パフォーマンスの監視・評価
    \item 公共サービス・民間サービスへのアクセス: 公的機関による給付金の受給資格の評価。信用力の評価（金融詐欺の検出は除く）。警察、消防、医療などの緊急通報の評価と優先順位付け。生命保険や健康保険のリスク評価と価格設定
    \item 法執行: 個人が犯罪被害者になるリスクの評価。ポリグラフ（嘘発見器）。犯罪捜査における証拠の信頼性評価。個人の犯罪リスク評価。犯罪捜査中のプロファイリング
    \item 移民・亡命・国境管理: ポリグラフ。不法移民や健康上のリスク評価。亡命、ビザ、居住許可の申請審査。個人の識別(渡航文書の検証は除く)
    \item 司法及び民主的プロセス: 事実の解釈や法律の適用にAIを使用すること。選挙結果や投票行動に影響を与えること(キャンペーンの最適化ツールなど、人間と直接対話しないものは除く)
\end{itemize}

ただし、上記に該当する場合でも、AIが「狭い手続き的なタスクを実行する」「人間が行った活動の結果を改善する」など、リスクが低いとみなされる特定の条件下では、ハイリスクから除外される例外がある。

重要な例外として上記に該当するAIシステムが、個人のプロファイリング(仕事のパフォーマンス、経済状況、健康、好み、行動などを評価するための個人データの自動処理)を行う場合は、常にハイリスクとみなされる。

\subsubsection{高リスクAIシステムの提供者に課される要求事項}

高リスクAIシステムの提供者は、以下の義務を果たす必要がある。

\begin{itemize}
    \item リスク管理システムの確立: AIシステムのライフサイクル全体を通じてリスクを管理する体制を構築すること
    \item データガバナンスの実施: 学習、検証、テストに用いるデータセットが、目的に対して適切かつ十分な代表性を持ち、可能な限りエラーがなく、完全であることを保証すること
    \item 技術文書の作成: 法令遵守を証明し、当局が評価するために必要な技術文書を準備すること
    \item 記録保持機能の設計: リスクを特定するために重要なイベント（ログ）を自動的に記録できるようシステムを設計すること
    \item 下流の展開者向け取扱説明書の提供: システムを導入する事業者（展開者）が法令を遵守できるよう、適切な使用方法を記載した説明書を提供すること
    \item 人間による監視（ヒューマン・オーバーサイト）の実装: 展開者が人間による適切な監視を行えるようシステムを設計すること
    \item 適切なレベルの正確性、堅牢性、サイバーセキュリティの確保
    \item 品質管理システムの確立: 法令遵守を確実にするための品質管理体制を構築すること
\end{itemize}

\subsubsection{新たな規制対象:汎用AI(GPAI)モデル}
AI Actは、特定の用途に限定されないGPAIモデル、特に社会に広範な影響を与える「システミックリスク」を伴うモデルに対して、新たな義務を課している。

\subsubsection*{GPAIの定義}

GPAIの定義は以下の通りです。

\begin{itemize}
    \item 汎用AIモデル(GPAIモデル): 大量のデータを用いて自己教師あり学習などで訓練され、幅広いタスクを高い能力で実行できる、著しく汎用的なAIモデル。特定の製品として市場に出る前の、研究・開発・プロトタイピング段階のモデルは含まれない
    \item 汎用AIシステム(GPAIシステム): GPAIモデルを基盤とし、直接利用されたり、他のAIシステムに統合されたりするなど、多様な目的で利用できるAIシステム
\end{itemize}


\subsubsection*{全てのGPAIモデル提供者に課される義務}

GPAIモデルを提供する全ての事業者は、以下の義務を負います。

\begin{itemize}
    \item 技術文書の作成: 訓練・テストのプロセスや評価結果を含む技術文書を作成すること
    \item 下流の提供者への情報提供: GPAIモデルを自社のAIシステムに統合しようとする事業者(下流の提供者)に対し、そのモデルの能力や限界を理解させ、法令遵守を可能にするための情報や文書を提供すること
    \item 著作権指令を尊重する方針の確立: EUの著作権法を遵守するための方針を策定すること
    \item 訓練コンテンツの要約の公開: モデルの訓練に使用したコンテンツについて、十分に詳細な要約を公開すること
\end{itemize}

パラメータ(重み、モデルのアーキテクチャ、使用法など)が公開されている自由かつオープンなライセンスのGPAIモデルは、上記の3つ目と4つ目の義務のみを遵守すればよいとされている。
ただし、そのモデルが後述の「システミックリスク」を持つ場合は、この例外は適用されない。



\subsubsection*{システミックリスクを伴うGPAIモデル}

モデルの訓練に用いられた累積計算量が1025FLOPs(浮動小数点演算)を超える場合、「システミックリスク」を持つと見なされる。
その提供者は、この基準に達した場合、2週間以内に欧州委員会に通知する義務がある。

追加の義務は以下の通りである。

\begin{itemize}
    \item モデル評価の実施: システミックリスクを特定・軽減するため、敵対的テストを含むモデル評価を実施し、文書化すること
    \item システミックリスクの評価と軽減: 潜在的なシステミックリスクとその源泉を評価し、軽減措置を講じること
    \item 重大インシデントの追跡、文書化、報告: 重大なインシデントと是正措置の可能性について、遅滞なくAIオフィスおよび関連する国内管轄当局に報告すること
    \item サイバーセキュリティの確保: 適切なレベルのサイバーセキュリティ保護を保証すること
\end{itemize}


\subsubsection{限定的リスクと最小リスクAI}

上記以外にも、AI Actはリスクに応じた規律を定めている。

\begin{itemize}
    \item 限定的リスク:チャットボットやディープフェイクのように、人間がAIと対話していることを認識できない可能性がある場合、その旨を利用者に開示する透明性義務が課される
    \item 最小リスク:上記のいずれにも該当しない多くのAIアプリケーションは、最小リスクとみなされ、原則として規制の対象外となる
\end{itemize}


\subsubsection{執行と罰則}

AI Actの実効性を担保するため、EUレベルで監督を行う「AIオフィス」が設置される。
規則に違反した事業者には、最大で全世界の年間売上高の7\%または3500万ユーロのいずれか高い方が制裁金として科される可能性があり、極めて厳しい罰則規定となっている。

\subsection{アメリカ}

アメリカでは、政権交代がAI政策の方向性に根本的な影響を与えている。バイデン前政権は大統領令により、AIの安全性やセキュリティ、国民の権利保護を重視し、安全を確保するための規制を強化した。
一方、現在のトランプ政権では、イノベーションの妨げとなる規制の撤廃を行い、AI開発が自由に行うことができるような方針での政策を行っている。

このように、国家内においても「国民の安全」と「イノベーションの加速」という二つの目的の間で大きな方針転換が見られるアメリカの事例は、日本がAI規制のあり方を検討する上で、きわめて重要な示唆を与える。
本節では、これら二つの政権下における具体的な政策内容を詳細に分析する。

\subsubsection{バイデン前政権による政策}

バイデン前政権による政策は、国民の安全を優先し、AIがもたらすリスクを管理することを目的とした方針であった。
その集大成が、2023年10月30日に公表された「The Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence」(人工知能の安全・安心・信頼できる開発と利用に関する大統領令)である。
この大統領令は、包括的な法律の制定を待たず、既存の行政機関の権限を活用してAIのリスクに対応するよう命じるもので、その主な内容は以下の通りである。

\subsubsection*{AI技術の安全・安心の確保}

\begin{itemize}
    \item デュアルユース基盤モデルに関する報告義務
    \item IaaS業者による外国ユーザー報告義務
    \item 重要なインフラのサイバーセキュリティ強化
    \item AIによる生成コンテンツのウォーターマーク検討
\end{itemize}

\subsubsection*{イノベーションと競争力強化}

\begin{itemize}
    \item AI人材の確保
    \item 特許権・IP法の明確化
\end{itemize}

\subsubsection*{労働者支援}

\begin{itemize}
    \item 労働市場におけるAI活用と影響に関するレポートとガイドラインの発行
\end{itemize}

\subsubsection*{公平と公民権推進}

\begin{itemize}
    \item 連邦政府機関での公民権強化、構成で公平な司法制度の確保
\end{itemize}

\subsubsection*{消費者、患者、交通機関利用者、学生の保護}

\begin{itemize}
    \item ヘルスケア、運輸、教育、通信関連の連邦政府機関によるAI活用推進
\end{itemize}

\subsubsection*{米国の国際的リーダーシップ推進}

\begin{itemize}
    \item 米国のAI基準・フレームワークの海外推進
\end{itemize}

%pwcまとめ

\subsubsection{トランプ政権による政策}

トランプ政権では、アメリカが人工知能における世界的優位の確立を目指し、他国との競争に勝利することで、人類の繁栄、経済競争力の強化、そしてアメリカ国民の国家安全保障という新たな時代を迎えることを目的としている。
この認識に基づき、「イノベーションの加速」、「インフラの構築」、「国際外交・安全保障における主導権」という3つの柱に基づくAIアクションプランを策定した。

それぞれの項目は以下の通りである。

\subsubsection*{AIイノベーションを加速}

\begin{itemize}
    \item 煩雑な規制と煩雑な手続きの廃止
    \item Frontier AIが言論の自由とアメリカの価値観を守ることを保証
    \item オープンソースおよびオープンウェイトAIの奨励
    \item AI導入を可能にする
    \item AI時代のアメリカの労働者のエンパワーメント
    \item 次世代製造業をサポート
    \item AIを活用した科学への投資
    \item 世界クラスの科学データセットを構築する
    \item AI科学の進歩
    \item AIの解釈可能性、制御性、堅牢性のブレークスルーに投資する
    \item AI評価エコシステムの構築
    \item 政府におけるAI導入の加速
    \item 国防総省におけるAI導入を推進
    \item 民間および政府のAIイノベーションを保護する
    \item 法制度における合成メディアとの闘い
\end{itemize}

\subsubsection*{アメリカのAIインフラを構築する}

\begin{itemize}
    \item セキュリティを確保しながら、半導体製造施設やエネルギーインフラの許可手続きを簡素化
    \item AIイノベーションのペースに合わせたグリッドを開発する
    \item アメリカの半導体製造業の復活
    \item 軍事および諜報機関向けの高セキュリティデータセンターを構築
    \item AIインフラのための熟練した人材を育成する
    \item 重要インフラのサイバーセキュリティ強化  
    \item セキュアバイデザインAIテクノロジーとアプリケーションの推進
    \item AIインシデント対応のための成熟した連邦政府の能力を促進する
\end{itemize}

\subsubsection*{国際AI外交と安全保障をリードする}

\begin{itemize}
    \item アメリカのAIを同盟国やパートナーに輸出する
    \item 国際統治機関における中国の影響に対抗する
    \item AIコンピューティングの輸出管理の強化
    \item 既存の半導体製造輸出規制の抜け穴を塞ぐ
    \item 世界規模で保護対策を整合させる
    \item 米国政府がフロンティアモデルにおける国家安全保障リスクの評価の最前線に立つことを確保する
    \item バイオセキュリティへの投資
\end{itemize}

\subsubsection{両政権の政策比較と日本への示唆}

バイデン前政権とトランプ現政権の政策は、正反対に見えるが、共通の目的意識も存在する。
しかし、ここまでの違いがなぜあるのか。「優先順位」「共通点」という軸から比較する。

\subsubsection*{優先順位の対立：「国民の安全」と「国家の覇権」}

両政権の最大の違いは、AIガバナンスにおける最優先事項にある。
バイデン前政権の政策の中心は「国民の安全と信頼の確保」であった。大統領令が掲げる「AI技術の安全・安心の確保」や「公平と公民権推進」「労働者支援」といった項目は、AIがもたらすリスクから国民を保護することを第一の目的としていたことを示している。

対照的に、トランプ現政権の政策は「国家間の技術覇権競争」という認識が起点となっている。
「イノベーションの加速」や「国際AI外交と安全保障をリードする」といった柱は、AIを国家の競争力を左右する戦略的資産とみなしている。

\subsubsection*{共通点と日本への示唆}

アプローチは正反対だが、両政権とも「AIにおける米国のリーダーシップを維持・強化する」という最終目的は完全に一致している。
また、AIの研究開発や人材育成に積極的に投資する「推進」の側面も共通している。

アメリカの事例は、AIという新技術に対し、「国民の安全」と「国家の覇権」という2つの価値が、政権交代によっていかに両極端に振れうるかという不安定性を示している。

これは、日本が「国民の安全」と「イノベーション」のバランスをどう安定させるかという極めて重要な論点を提示している。

\subsubsection{その他：州による規制}
現在進行形なのであとでかきます。

\subsection{中国}

\subsection{韓国}

\subsection{国連}

\section{各国のアプローチの違いと、メリットデメリットについて}
