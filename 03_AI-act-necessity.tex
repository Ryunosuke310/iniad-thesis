\chapter{AI規制法の必要性について}
本章では、AIに対する法的な規制がなぜ求められるのかを明らかにする。
そのために、まずAIの研究開発や利用に関する国際的な原則がどのように形成されてきたかを概観し、
次にAI規制に類似した生命倫理などの分野から得られる示唆を整理することで、AI規制の必要性を多角的に論じる。

\section{AI原則について} %05-1
AIを社会に実装するにあたり、その無秩序な開発や利用を防ぐための共通理念の構築が求められてきた。
本節では、国際的なAIガバナンスの議論を形作った3つの主要な原則を分析する。
議論の出発点となったのは、政府や研究者コミュニティが主導した「AIの研究開発原則」や「アシロマAI原則」であり、
これらはAIが従うべき倫理的・哲学的な理念を提示した。
そして、この理念的な議論を現実の政策に接続する役割を果たしたのが、経済協力開発機構(OECD)による原則を承認した「G20AI原則」である。
この「抽象的な理念から具体的な政策へ」という流れは、AIという新たな技術を社会がどのように受容しようとしてきたかの過程そのものを表している。

\subsection{AIの研究開発の原則} 
AIガバナンスに関する国際的な議論の礎となったのが、2016年のG7香川・高松情報通信大臣会合で示された「AIの研究開発原則」である。
AIが社会経済に革命的な変化をもたらすとの認識のもと、G7各国が中心となり、AI開発者が留意すべき基本原則について議論が行われた。
%冒頭発言より引用しているため、あとでつなげるのを忘れずに
この原則は、以下の8つの項目で構成されている。
\begin{enumerate}
  \item 透明性の原則 : AIネットワークシステムの動作の説明可能性及び検証可能性を確保すること
  \item 利用者支援の原則 : AIネットワークシステムが利用者を支援するとともに、利用者に選択の機会を適切に提供するよう配慮すること
  \item 制御可能性の原則 : 人間によるAIネットワークシステムの制御可能性を確保すること
  \item セキュリティ確保の原則 : AIネットワークシステムの頑健性及び信頼性を確保すること
  \item 安全保護の原則 : AIネットワークシステムが利用者及び第三者の生命・身体の安全に危害を及ぼさないように配慮すること
  \item プライバシー保護の原則 : AIネットワークシステムが利用者及び第三者のプライバシーを侵害しないように配慮すること
  \item 倫理の原則 : ネットワーク化されるAIの研究開発において、人間の尊厳と個人の自立を尊重すること
  \item アカウンタビリティの原則 : ネットワーク化されるAIの研究開発者が利用者等関係ステークホルダーへのアカウンタビリティを果たすこと
\end{enumerate}

これらの原則は、AIがもたらすリスクに対して国際社会が初めて共通の方向性を示したという点で歴史的な意義を持つ。
特に、透明性やアカウンタビリティといった概念は、その後のEUのAI Actをはじめとする各国の法規制の議論において、
中核的な要素として引き継がれている。

しかしこれらは、あくまで国家間の法的拘束力のない原則であり、事業者の自主的な取組に委ねられている。
したがって、これらの原則の実効性を担保し、社会全体でリスクを管理するために、より拘束力のあるハードローが必要なのではないかという問いが生まれる。


\subsection{アシロマ原則} 

\subsection{G20AI原則}

\section{生命倫理とAI倫理} %05-2

\subsection{フロリディの生命倫理}

\subsection{生命倫理とAI倫理の接点}

%ここいったん保留にします%

%\section{ソフトローとハードローの選択} %05-3

%\subsection{ソフトロー}

%\subsection{ハードロー}

%\subsection{日本に合わせたアプローチ}