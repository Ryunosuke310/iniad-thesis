\chapter{AI規制法の必要性について}
本章では、AIに対する規制がなぜ求められるのかを明らかにする。
そのために、AIの研究開発や利用に関する国際的な原則がどのように形成されてきたかを概観することにより、
AI規制の必要性を論じる。

\section{AI原則について} %05-1
AIガバナンスに関する国際的な議論は、技術の進展に伴い、理念の提示から具体的な政策指針へと深化してきた。
本節では、その流れを形作ったG7、G20、そして広島AIプロセスという3つの重要な国際合意を分析する。

しかし、本節の目的は、単にこれらの原則の歴史的変遷を追うことではない。むしろ、これらの原則が掲げる「透明性」や「安全性」、「アカウンタビリティ」を実現するための方法について焦点を当てる。
なぜなら、これらの理想的な価値観を社会の隅々にまで実効的に浸透させるためには、事業者の自主的な取り組みだけでは不十分だからである。
本節は、「原則が掲げる理想の内容そのものが、法的拘束力の必要性を示唆している」という視点から、AIに対する法規制(ハードロー)がなぜ求められるのか、その論拠を明らかにする。


\subsection{AIの研究開発の原則} 
AIガバナンスに関する国際的な議論の礎となったのが、2016年のG7香川・高松情報通信大臣会合で示された「AIの研究開発原則」である。\cite{aikenkyukaihatugensoku:online}
AIが社会経済に革命的な変化をもたらすとの認識のもと、G7各国が中心となり、AI開発者が留意すべき基本原則について議論が行われた。\cite{soumu2016g7}
%冒頭発言より引用しているため、あとでつなげるのを忘れずに

この原則は、以下の8つの項目で構成されている。

\begin{enumerate}
  \item 透明性の原則 : AIネットワークシステムの動作の説明可能性及び検証可能性を確保すること
  \item 利用者支援の原則 : AIネットワークシステムが利用者を支援するとともに、利用者に選択の機会を適切に提供するよう配慮すること
  \item 制御可能性の原則 : 人間によるAIネットワークシステムの制御可能性を確保すること
  \item セキュリティ確保の原則 : AIネットワークシステムの頑健性及び信頼性を確保すること
  \item 安全保護の原則 : AIネットワークシステムが利用者及び第三者の生命・身体の安全に危害を及ぼさないように配慮すること
  \item プライバシー保護の原則 : AIネットワークシステムが利用者及び第三者のプライバシーを侵害しないように配慮すること
  \item 倫理の原則 : ネットワーク化されるAIの研究開発において、人間の尊厳と個人の自立を尊重すること
  \item アカウンタビリティの原則 : ネットワーク化されるAIの研究開発者が利用者等関係ステークホルダーへのアカウンタビリティを果たすこと
\end{enumerate}

これらの原則は、AIがもたらすリスクに対して国際社会が初めて共通の方向性を示したという点で歴史的な意義を持つ。
特に、透明性やアカウンタビリティといった概念は、その後のEUのAI Actをはじめとする各国の法規制の議論において、
中核的な要素として引き継がれている。

なお、この「AIの研究開発原則」は、21年ぶりに開催されたG7香川・高松情報通信大臣会合において、
日本が主導的役割を果たし提案したものであり、その後の国際的なAI研究開発原則に関する議論の端緒となった、画期的な成果である。


\subsection{G20AI原則}
G7で示された研究開発原則の議論を踏まえ、具体的な検討は、経済協力開発機構(OECD)で行われ、2019年5月に42か国が「AIに関するOECD原則」を採択した。
この原則と同様の内容が2019年6月に開催されたG20大阪サミットで「G20 AI原則」として採択された。\cite{g20aigensokuhuzuisyo:online}
OECD原則を基に、G20というより広範な国家間で承認された初のAI原則となった。

G7原則が開発者向けの理念であったのに対し、G20AI原則は各国政府が国内政策を推進する上での指針も含まれており、
AIガバナンスが具体的な制度設計の段階へと移行したことを示す重要な転換点といえる。
また、G20国家間でAIに対する考え方が必ずしも一致していない状況下において、G20として合意文書をまとめた成果は極めて大きい。

G20AI原則は、大きく5つの補完的な価値に基づく原則と、
5つの国内政策及び国際協力に関する勧告で構成されている。その全項目は以下のとおりである。

\subsection*{価値に関する原則} %目次に表示されない
\begin{description}
  \item[1. 包摂的な成長、持続可能な開発及び幸福]
  \item[2. 人間中心の価値観及び公平性]
  \item[3. 透明性及び説明可能性]
  \item[4. 頑健性、セキュリティ及び安全性]
  \item[5. アカウンタビリティ]
\end{description}

\subsection*{政策に関する勧告}
\begin{description}
  \item[1. AIの研究開発への投資]
  \item[2. AIのためのデジタル・エコシステムの育成]
  \item[3. AIを推進するための政策環境の整備]
  \item[4. 人材育成及び労働市場変革への準備]
  \item[5. 国際協力]
\end{description}

G20AI原則に示された項目の中でも、特に「1.2 人間中心の価値観及び公平性」「1.3 透明性及び説明可能性」「1.4 頑健性、セキュリティ及び安全性」「1..5 アカウンタビリティ」は、
AIを社会に実装する上での根源的な課題に応えようとするものであり、その後の各国の法規制の議論において中核的な論点であり続ける。
これら4つの原則は独立しているのではなく、相互に連携することで「信頼できるAI」という目標を達成するための論理的な枠組みを形成している。

\subsection{広島AIプロセス}

2019年のG20原則で確立された国際的な共通認識は、2022年末からの生成AIの爆発的な普及により、新たな局面を迎えることとなった。
G20原則が主に専門家による利用を想定した広範なAIを対象としていたのに対し、生成AIは一般市民にまで利用が拡大したため、
偽情報の拡散や著作権侵害といった問題が浮上した。

この新たな課題に対応するため、2023年にG7議長国であった日本が主導して立ち上げたのが「広島AIプロセス」である。
このプロセスの最大の意義は、生成AIに対応したガバナンスの国際的な枠組みを構築しようとした点にある。


広島AIプロセスで作成された「高度なAIシステムを開発する組織向けの広島プロセス国際行動規範」\cite{hiroshimaaiprocess:online}は以下のとおりである。

\begin{enumerate}
  \item AIライフサイクル全体にわたるリスクを特定、評価、軽減するために、高度なAIシステムの開発全体を通じて、その導入前及び市場投入前も含め、適切な措置を講じる。
  \item 市場投入を含む導入後、脆弱性、及び必要に応じて悪用されたインシデントやパターンを特定し緩和する。
  \item 高度なAIシステムの能力、限界、適切・不適切な使用領域を公表し、十分な透明性の確保を支援することで、アカウンタビリティの向上に貢献する。
  \item 産業界、政府、市民社会、学界を含む、高度なAIシステムを開発する組織間での責任ある情報共有とインシデントの報告に向けて取り組む。
  \item 個人情報保護方針及び緩和策を含む、リスクベースのアプローチに基づくAIガバナンス及びリスク管理方針を策定し、実施し、開示する。
  \item AIのライフサイクル全体にわたり、物理的セキュリティ、サイバーセキュリティ、内部脅威に対する安全対策を含む、強固なセキュリティ管理に投資し、実施する。
  \item 技術的に可能な場合は、電子透かしやそのほかの技術等、ユーザーがAIが生成したコンテンツを識別できるようにするための、信頼できるコンテンツ認証及び来歴のメカニズムを開発し、導入する。
  \item 社会的、安全、セキュリティ上のリスクを軽減するための研究を優先し、効果的な軽減策への投資を優先する。
  \item 世界の最大の課題、特に気候危機、世界保健、教育等(ただしこれらに限定されない)に対処するため、高度なAIシステムの開発を優先する。
  \item 国際的な技術規格の開発を推進し、適切な場合にはその採用を推進する。
  \item 適切なデータインプット対策を実施し、個人データおよび知的財産を保護する。
\end{enumerate}

広島AIプロセスは、G20原則で示された「人間中心」や「透明性」といった理念を引き継ぎつつも、議論の焦点をより具体的な「リスクの特定」と「対策の実践」へと移行させた。
その象徴的な成果が、先進的なAIシステムを開発する事業者向けの「国際行動規範」の策定である。
これは、AIガバナンスが抽象的な理念の共有から、具体的な行動を促すルールの策定へと、議論のフェーズを一段進めたことを示している。

\subsection{国際原則の評価と各国の責務}

これまでに概観したG7、G20、広島AIプロセスという一連の国際原則は、無秩序なAI開発を防ぎ、世界共通の方向性を示す「共通言語」として極めて重要な意義を持つ。
これらの原則は、全ての国が守るべき倫理的な最低基準を確立したと評価できる。

しかしこれらの原則は、その性質上、普遍的かつ抽象的であるという限界も内包している。
多様な政治体制、法文化、経済状況を持つ国家間の合意形成を目的とするため、必然的に最大公約数的な表現にとどまらざるを得ないからだ。
したがって、国際原則はAIガバナンスの「天井」ではなく、あくまで「土台」としてとらえるべきである。
この土台の上に、各国の固有の状況に合わせた、より具体的で実効性のある規制を構築する責務が、それぞれの国家にはある。

結論として、「国際AI原則」は「何を」目指すべきかという倫理的なコンパスを提供するが、「どのように」それを実現するかという具体的な制度設計は、各国の主体的な判断に委ねられている。


%\ここなくそうと思います。

%\section{生命倫理とAI倫理} %05-2

%\subsection{フロリディの生命倫理}

%\subsection{生命倫理とAI倫理の接点}



