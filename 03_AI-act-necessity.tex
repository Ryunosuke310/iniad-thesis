\chapter{AI規制法の必要性について}
本章では、AIに対する法的な規制がなぜ求められるのかを明らかにする。
そのために、まずAIの研究開発や利用に関する国際的な原則がどのように形成されてきたかを概観し、
次にAI規制に類似した生命倫理などの分野から得られる示唆を整理することで、AI規制の必要性を多角的に論じる。

\section{AI原則について} %05-1
AIガバナンスに関する国際的な議論は、特に政府が主導する政策として具体化されてきた。
本節では、その流れを形作った2つの重要な国際合意、すなわち2016年の「G7 AI研究開発原則」と、
その議論を発展させ、OECD加盟国の共通認識となった2019年の「G20 AI原則」を分析する。
この二つの原則の変遷を追うことで、AIに対する国際社会の向き合い方がどのように深化し、
現在の法規制の議論に繋がっていったのかを明らかにする。

\subsection{AIの研究開発の原則} 
AIガバナンスに関する国際的な議論の礎となったのが、2016年のG7香川・高松情報通信大臣会合で示された「AIの研究開発原則」である。
AIが社会経済に革命的な変化をもたらすとの認識のもと、G7各国が中心となり、AI開発者が留意すべき基本原則について議論が行われた。
%冒頭発言より引用しているため、あとでつなげるのを忘れずに
この原則は、以下の8つの項目で構成されている。

\begin{enumerate}
  \item 透明性の原則 : AIネットワークシステムの動作の説明可能性及び検証可能性を確保すること
  \item 利用者支援の原則 : AIネットワークシステムが利用者を支援するとともに、利用者に選択の機会を適切に提供するよう配慮すること
  \item 制御可能性の原則 : 人間によるAIネットワークシステムの制御可能性を確保すること
  \item セキュリティ確保の原則 : AIネットワークシステムの頑健性及び信頼性を確保すること
  \item 安全保護の原則 : AIネットワークシステムが利用者及び第三者の生命・身体の安全に危害を及ぼさないように配慮すること
  \item プライバシー保護の原則 : AIネットワークシステムが利用者及び第三者のプライバシーを侵害しないように配慮すること
  \item 倫理の原則 : ネットワーク化されるAIの研究開発において、人間の尊厳と個人の自立を尊重すること
  \item アカウンタビリティの原則 : ネットワーク化されるAIの研究開発者が利用者等関係ステークホルダーへのアカウンタビリティを果たすこと
\end{enumerate}

これらの原則は、AIがもたらすリスクに対して国際社会が初めて共通の方向性を示したという点で歴史的な意義を持つ。
特に、透明性やアカウンタビリティといった概念は、その後のEUのAI Actをはじめとする各国の法規制の議論において、
中核的な要素として引き継がれている。

なお、この「AIの研究開発原則」は、21年ぶりに開催されたG7香川・高松情報通信大臣会合において、
日本が主導的役割を果たし提案したものであり、その後の国際的なAI研究開発原則に関する議論の端緒となった、画期的な成果である。


\subsection{G20AI原則}
G7で示された研究開発原則の議論を踏まえ、具体的な検討は、経済協力開発機構(OECD)で行われ、2019年5月に42か国が「AIに関するOECD原則」を採択した。
この原則と同様の内容が2019年6月に開催されたG20大阪サミットで「G20 AI原則」として採択された。
OECD原則を基に、G20というより広範な国家間で承認された初のAI原則となった。

G7原則が開発者向けの理念であったのに対し、G20AI原則は各国政府が国内政策を推進する上での指針も含まれており、
AIガバナンスが具体的な制度設計の段階へと移行したことを示す重要な転換点といえる。
また、G20国家間でAIに対する考え方が必ずしも一致していない状況下において、G20として合意文書をまとめた成果は極めて大きい。

G20AI原則は、大きく5つの補完的な価値に基づく原則と、
5つの国内政策及び国際協力に関する勧告で構成されている。その全項目は以下のとおりである。

\subsection*{価値に関する原則} %目次に表示されません
\begin{description}
  \item[1. 包摂的な成長、持続可能な開発及び幸福]
  \item[2. 人間中心の価値観及び公平性]
  \item[3. 透明性及び説明可能性]
  \item[4. 頑健性、セキュリティ及び安全性]
  \item[5. アカウンタビリティ]
\end{description}

\subsection*{政策に関する勧告}
\begin{description}
  \item[1. AIの研究開発への投資]
  \item[2. AIのためのデジタル・エコシステムの育成]
  \item[3. AIを推進するための政策環境の整備]
  \item[4. 人材育成及び労働市場変革への準備]
  \item[5. 国際協力]
\end{description}


\subsection{G7原則からG20AI原則への展開と考察}

考察をこっちにまとめた方がよくまとまる？

しかしこれらは、あくまで国家間の法的拘束力のない原則であり、事業者の自主的な取組に委ねられている。
したがって、これらの原則の実効性を担保し、社会全体でリスクを管理するために、より拘束力のあるハードローが必要なのではないかという問いが生まれる。


\section{生命倫理とAI倫理} %05-2

\subsection{フロリディの生命倫理}

\subsection{生命倫理とAI倫理の接点}

%ここいったん保留にします%

%\section{ソフトローとハードローの選択} %05-3

%\subsection{ソフトロー}

%\subsection{ハードロー}

%\subsection{日本に合わせたアプローチ}